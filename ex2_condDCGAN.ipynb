{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Deep Convolutional Generative Adversarial Network (cDCGAN)\n",
    "## Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as kb\n",
    "\n",
    "\n",
    "from IPython import display\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some utils from:\n",
    "!git clone https://github.com/dlanci/UZHMLWorkshop2020-GAN\n",
    "os.chdir('UZHMLWorkshop2020-GAN/')\n",
    "from utils.utils import load_dataset\n",
    "from utils.utils import generate_and_save_images_conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset file\n",
    "!wget -q --show-progress -O batch0.pickle \"https://www.dropbox.com/s/wn8ilvp8k67grz4/batch0.pickle?dl=0\";\n",
    "!wget -q --show-progress -O batch1.pickle \"https://www.dropbox.com/s/5vjme0o8drbi0v4/batch1.pickle?dl=0\";\n",
    "!wget -q --show-progress -O batch2.pickle \"https://www.dropbox.com/s/rz2b8c4911kb4iy/batch2.pickle?dl=0\";\n",
    "!wget -q --show-progress -O batch3.pickle \"https://www.dropbox.com/s/2wa94zzt7wq2002/batch3.pickle?dl=0\";\n",
    "!wget -q --show-progress -O batch4.pickle \"https://www.dropbox.com/s/icntmsval8nync5/batch4.pickle?dl=0\";\n",
    "tuple_, tot_evts = load_dataset(path='.', test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load the images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_pixels=48\n",
    "Y_pixels=48\n",
    "\n",
    "\n",
    "X_train=tuple_['reco_imgs'][0:np.int(tot_evts*0.9)]\n",
    "X_test=tuple_['reco_imgs'][np.int(tot_evts*0.9):tot_evts]\n",
    "\n",
    "\n",
    "maxval=X_train[np.where(X_train!=0)].max()\n",
    "\n",
    "X_train_norm = (X_train)/(maxval)\n",
    "X_test_norm = (X_test)/(maxval)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_train_norm[3].reshape(X_pixels,Y_pixels))\n",
    "plt.xlabel('X', fontsize=15)\n",
    "plt.ylabel('Y', fontsize=15)\n",
    "plt.title('A sample image', fontsize=15)\n",
    "plt.colorbar()\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(np.sum(X_train_norm,axis=(1,2,3)),bins=100);\n",
    "plt.xlabel('E (a.u.)', fontsize=15)\n",
    "plt.ylabel('dN/dE', fontsize=15)\n",
    "plt.title('Total energy deposit per image', fontsize=15)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16,5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load the labels dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=tuple_['all_tracks'][0:np.int(tot_evts*0.9)]\n",
    "y_test=tuple_['all_tracks'][np.int(tot_evts*0.9):tot_evts]\n",
    "\n",
    "\n",
    "\n",
    "y_train1=np.where(y_train[:,0:24]<0,0.,y_train[:,0:24])\n",
    "y_train2=np.where(y_train1[:,0:24]>48,0.,y_train1[:,0:24])\n",
    "y_train_norm=np.zeros_like(y_train)\n",
    "\n",
    "y_train_norm[:,0:24]=(y_train2)/48\n",
    "\n",
    "\n",
    "ymaxE = 6120\n",
    "y_train_norm[:,24:36]=(y_train[:,24:36])/(ymaxE)\n",
    "\n",
    "y_test1=np.where(y_test[:,0:24]<0,0,y_test[:,0:24])\n",
    "y_test2=np.where(y_test1[:,0:24]>48,0,y_test1[:,0:24])\n",
    "y_test_norm=np.zeros_like(y_test)\n",
    "y_test_norm[:,0:24]=(y_test2)/48\n",
    "\n",
    "y_test_norm[:,24:36]=(y_test[:,24:36])/(ymaxE)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_train_norm[:,0:12].flatten(),range=(0.001,1.1),bins=100);\n",
    "plt.xlabel('dN/dpX', fontsize=15)\n",
    "plt.ylabel('pX', fontsize=15)\n",
    "plt.title('pX distr', fontsize=15)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_train_norm[:,24:36].flatten(),range=(0.001,1.1),bins=100);\n",
    "plt.xlabel('real E (a.u.)', fontsize=15)\n",
    "plt.ylabel('dN/dE', fontsize=15)\n",
    "plt.title('real E distr', fontsize=15)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16,5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create Tensorflow Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_TRAIN_SIZE = np.int(tot_evts*0.9)\n",
    "BUFFER_TEST_SIZE = np.int(tot_evts*0.1)\n",
    "\n",
    "\n",
    "\n",
    "X_train_dataset = tf.data.Dataset.from_tensor_slices(X_train_norm)\n",
    "label_train_dataset = tf.data.Dataset.from_tensor_slices(y_train_norm)\n",
    "\n",
    "train_dataset=tf.data.Dataset.zip((X_train_dataset, label_train_dataset))\n",
    "train_dataset=train_dataset.shuffle(BUFFER_TRAIN_SIZE, \n",
    "                                      reshuffle_each_iteration=True)\n",
    "\n",
    "\n",
    "train_dataset=train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "it = iter(train_dataset)\n",
    "img, label = next(it)\n",
    "plt.imshow(img.numpy()[0].reshape(48,48))\n",
    "print(label[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dataset = tf.data.Dataset.from_tensor_slices(X_test_norm)\n",
    "label_test_dataset = tf.data.Dataset.from_tensor_slices(y_test_norm)\n",
    "\n",
    "test_dataset=tf.data.Dataset.zip((X_test_dataset, label_test_dataset))\n",
    "test_dataset=test_dataset.shuffle(BUFFER_TEST_SIZE, \n",
    "                                      reshuffle_each_iteration=True)\n",
    "\n",
    "\n",
    "test_dataset=test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "it = iter(train_dataset)\n",
    "img, label = next(it)\n",
    "plt.imshow(img.numpy()[0].reshape(48,48))\n",
    "print(label[0].numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Building the Generator model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model(z_dim, label_dim):\n",
    "    \n",
    "    n_nodes = 12*12\n",
    "    useb=False\n",
    "    \n",
    "    #initializer = tf.keras.initializers.TruncatedNormal(mean=0., stddev=1.)\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "    \n",
    "    label_input_init = layers.Input((label_dim,))\n",
    "    \n",
    "    label_input = layers.Dense(64 * n_nodes, use_bias=useb,kernel_initializer=initializer)(label_input_init)\n",
    "    label_input = layers.LeakyReLU(alpha=0.1)(label_input)\n",
    "    label_input_as_img = layers.Reshape((12,12, 64))(label_input)\n",
    "\n",
    "    \n",
    "    z_input_init = layers.Input((z_dim,))\n",
    "    z_input = layers.Dense(64 * n_nodes, use_bias=useb, kernel_initializer=initializer)(z_input_init)\n",
    "    z_input = layers.LeakyReLU(alpha=0.1)(z_input)\n",
    "    z_input = layers.Reshape((12, 12, 64))(z_input)\n",
    "\n",
    "\n",
    "    hid = layers.Concatenate(axis=3)([label_input_as_img, z_input])\n",
    "\n",
    "    hid = layers.Conv2DTranspose(filters=32,                           # number of output channels\n",
    "                                 kernel_size=(4,4),                    # size of the convolution kernel              \n",
    "                                 strides=(2,2),                        \n",
    "                                 padding='same',\n",
    "                                 use_bias=False)(hid)\n",
    "    #print(hid.shape)\n",
    "\n",
    "    \n",
    "    hid=layers.BatchNormalization()(hid)\n",
    "    hid=layers.LeakyReLU(alpha=0.2)(hid)\n",
    "    \n",
    "    \n",
    "    hid = layers.Conv2DTranspose(filters=16,\n",
    "                                 kernel_size=(5,5), \n",
    "                                 strides=(2,2), \n",
    "                                 padding='same',\n",
    "                                 use_bias=False)(hid)\n",
    "    \n",
    "    #print(hid.shape)\n",
    "    \n",
    "    hid=layers.BatchNormalization()(hid)\n",
    "    hid=layers.LeakyReLU(alpha=0.2)(hid)    \n",
    "    \n",
    "    out = layers.Conv2DTranspose(filters=1,\n",
    "                                 kernel_size=(5,5), \n",
    "                                 strides=(1,1), \n",
    "                                 padding='same',\n",
    "                                 use_bias=False,\n",
    "                                 activation='sigmoid')(hid)\n",
    "\n",
    "    #print(hid.shape)\n",
    "    \n",
    "    model = models.Model(inputs=[z_input_init,label_input_init], outputs=out)\n",
    "    \n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim=128 \n",
    "generator = make_generator_model(z_dim=noise_dim, label_dim=36)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Building the Discriminator model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model(label_dim):\n",
    "    \n",
    "    #initializer = tf.keras.initializers.TruncatedNormal(mean=0., stddev=1.)\n",
    "    initializer = tf.keras.initializers.GlorotNormal()    \n",
    "    n_nodes = X_pixels*Y_pixels\n",
    "    \n",
    "    label_input_init = layers.Input((label_dim,))\n",
    "    label_input = layers.Dense(n_nodes, kernel_initializer=initializer)(label_input_init)\n",
    "    label_input = layers.LeakyReLU(alpha=0.2)(label_input)\n",
    "    label_input = layers.Reshape((X_pixels,Y_pixels,1))(label_input)\n",
    "\n",
    "    \n",
    "    image_input_layer = layers.Input((X_pixels,Y_pixels,1))                     # Again define the input\n",
    "    \n",
    "    hid = layers.Concatenate(axis=3)([image_input_layer, label_input])\n",
    "\n",
    "    hid = layers.Conv2D(64, kernel_size=4, strides=2, padding='same')(hid) # Example usage\n",
    "    hid = layers.LeakyReLU(alpha=0.2)(hid)                                               # of a convolutional\n",
    "    hid = layers.Dropout(0.3)(hid)                                                       # layer\n",
    "    \n",
    "    #print(hid.output)\n",
    "    \n",
    "    hid = layers.Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "    hid = layers.LeakyReLU(alpha=0.2)(hid)\n",
    "    hid = layers.Dropout(0.3)(hid)\n",
    "    \n",
    "    #print(hid.output)\n",
    "    \n",
    "    feature = layers.Flatten()(hid)     #Here I call the output \"feature\" for future needs\n",
    "    \n",
    "    hid = layers.Dense(32)(feature)\n",
    "    hid = layers.LeakyReLU(alpha=0.2)(hid)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #dimensions of minibatch matrix\n",
    "    n_kernels=12\n",
    "    dim_kernel=12\n",
    "    \n",
    "    mb_discr = layers.Dense(n_kernels*dim_kernel)(hid)\n",
    "    mb_discr = layers.Reshape((n_kernels,dim_kernel))(mb_discr)  #Matrix M\n",
    "    \n",
    "    diffs = kb.expand_dims(mb_discr, 3)-kb.expand_dims(kb.permute_dimensions(mb_discr, [1, 2, 0]), 0)\n",
    "    abs_diffs = kb.sum(kb.abs(diffs), axis=2)\n",
    "    \n",
    "    minibatch_features = kb.sum(kb.exp(-abs_diffs),2)\n",
    "    print(minibatch_features.shape)# (None, n_kernels)\n",
    "    hid=layers.Concatenate()([hid, minibatch_features])\n",
    "\n",
    "    \n",
    "    out = layers.Dense(1)(hid) #note that we don't activate the last layer of the discriminator\n",
    "                               #as the loss function we will use requires the unactivated output\n",
    "    \n",
    "    model = models.Model(inputs=[image_input_layer, label_input_init], outputs=[out, feature])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model(36)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal((1, noise_dim))\n",
    "generated_image = generator([noise,label[0].numpy().reshape(-1,36)], training=False)\n",
    "plt.imshow(generated_image[0,:,:,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision, feature = discriminator([generated_image,label[0].numpy().reshape(-1,36)])\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Definition of the Losses\n",
    "\n",
    "In the next step we will define the functions to be minimized during the training process. The two models (G,D) participate in a non-cooperative game and try to minimize two different loss functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output, eps=1e-3):\n",
    "\n",
    "    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=real_output,\n",
    "                #labels=tf.ones_like(real_output))) #one sided label smoothing\n",
    "                labels=(1-eps)*tf.ones_like(real_output))) #one sided label smoothing\n",
    "    \n",
    "    \n",
    "    fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=fake_output,\n",
    "                labels=tf.zeros_like(fake_output)))\n",
    "    \n",
    "    total_loss = real_loss + fake_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)   #define the minimization algorithm here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss_GAN(fake_output, eps=1e-3):\n",
    "    gan_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=fake_output,\n",
    "                #labels=tf.ones_like(fake_output))) \n",
    "                labels=(1-eps)*tf.ones_like(fake_output))) #one sided label smoothing\n",
    "    return gan_loss\n",
    "    \n",
    "def generator_loss_CYCLIC(true_images, fake_images):\n",
    "    \n",
    "    cyclic_loss = tf.reduce_mean(tf.abs(tf.cast(fake_images,tf.float32)-tf.cast(true_images,tf.float32)))\n",
    "      \n",
    "    return cyclic_loss\n",
    "\n",
    "\n",
    "def generator_loss_FEATURE(true_features, fake_features):\n",
    "    gan_loss= tf.sqrt(tf.reduce_mean(tf.pow(true_features-fake_features,2)))\n",
    "    return gan_loss\n",
    "\n",
    "  \n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)   #define the minimization algorithm here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Set up the training cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tensorboard for metrics inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our metrics\n",
    "\n",
    "d_train_loss = tf.keras.metrics.Mean('d_train_loss', dtype=tf.float32)\n",
    "g_train_loss = tf.keras.metrics.Mean('g_train_loss', dtype=tf.float32)\n",
    "d_train_accuracy_on_real = tf.keras.metrics.BinaryCrossentropy('train_accuracy_on_real', from_logits=True)\n",
    "d_train_accuracy_on_fake = tf.keras.metrics.BinaryCrossentropy('train_accuracy_on_fake', from_logits=True)\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "os.makedirs('./condGAN/logs/gradient_tape/', exist_ok=True)\n",
    "train_log_dir = './condGAN/logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 The train step function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will reuse this seed overtime (so it's easier)\n",
    "num_examples_to_generate = 32\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "\n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    \n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as gen_tape, tf.GradientTape(persistent=True) as disc_tape:\n",
    "        \n",
    "        generated_images = generator([noise, labels], training=True)\n",
    "    \n",
    "        real_output, real_feature = discriminator([images, labels], training=True)\n",
    "        fake_output, fake_feature = discriminator([generated_images, labels], training=True)\n",
    "\n",
    "        #gen_loss_GAN = generator_loss_GAN(fake_output)\n",
    "        gen_loss_GAN = gen_loss = generator_loss_FEATURE(real_feature, fake_feature)\n",
    "        gen_loss_CYCLIC = generator_loss_CYCLIC(generated_images, images)        \n",
    "        \n",
    "\n",
    "        gen_loss = gen_loss_GAN+0.1*gen_loss_CYCLIC\n",
    "        \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    \n",
    "    for i in range(1):\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    \n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    d_train_loss(disc_loss)\n",
    "    g_train_loss(gen_loss)\n",
    "    d_train_accuracy_on_real(tf.ones_like(real_output), real_output)\n",
    "    d_train_accuracy_on_fake(tf.zeros_like(fake_output), fake_output)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "checkpoint_dir = './condGAN/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\"\"\"\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    it = iter(test_dataset)\n",
    "    X_test, label_test = next(it)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "            \n",
    "        for image_batch, label_batch in train_dataset:\n",
    "            \n",
    "            g_loss, d_loss = train_step(image_batch, label_batch)\n",
    "            \n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('d_loss', d_train_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('g_loss', g_train_loss.result(), step=epoch)            \n",
    "            tf.summary.scalar('d_accuracy_on_fake', d_train_accuracy_on_fake.result(), step=epoch)\n",
    "            tf.summary.scalar('d_accuracy_on_real', d_train_accuracy_on_real.result(), step=epoch)            \n",
    "                  \n",
    "            \n",
    "        # Produce images for the GIF as we go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images_conditional(generator,\n",
    "                                 epoch + 1,\n",
    "                                 seed, X_test, label_test, maxval)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Save a checkpoint of the model every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "            \n",
    "\n",
    "        print ('Time for epoch {0} is {1} sec'.format(epoch + 1, datetime.datetime.now()-start))\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    #display.clear_output(wait=True)\n",
    "    \n",
    "    #generate_and_save_images_conditional(generator,\n",
    "    #                           epochs,\n",
    "    #                           seed, X_test, label_test, maxval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./condGAN/logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
